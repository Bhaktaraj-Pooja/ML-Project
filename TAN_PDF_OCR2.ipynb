{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PDF_OCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhaktaraj-Pooja/ML-Project/blob/main/TAN_PDF_OCR2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fINzrw1GnVv6"
      },
      "source": [
        "# Get total from Invoices of Restraurant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEBb2O5_8r29"
      },
      "source": [
        "Step 1) Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TziuumQDnUQZ",
        "outputId": "42a8f5ce-1cac-460a-90a3-ec6c48aa3ff7"
      },
      "source": [
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev\n",
        "!pip install pdf2image\n",
        "!apt-get install poppler-utils\n",
        "!pip install pytesseract\n",
        "import PIL\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from pdf2image import convert_from_path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.filters import threshold_local\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import re\n",
        "from pytesseract import Output\n",
        "import pandas as pd"
      ],
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libtesseract-dev is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.7/dist-packages (1.15.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pdf2image) (7.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (0.62.0-2ubuntu2.12).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzdIbKVFOF79",
        "outputId": "4cc1fea5-e0ac-4b3e-e1ad-7f818c2ed9d5"
      },
      "source": [
        "#Store folder path in variable\n",
        "folder = \"/content/drive/MyDrive/OCR_DataSet/Test/\"\n",
        "\n",
        "#Get all pdf files in the path\n",
        "files = [file for file in listdir(folder) if isfile(join(folder, file)) and file.endswith('.pdf')]\n",
        "print(files)"
      ],
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['TE_131.pdf', 'TE_158.pdf', 'TE_160.pdf', 'TE_155.pdf', 'TE_159.pdf', 'TE_161.pdf', 'TE_162.pdf', 'TE_157.pdf', 'TE_152.pdf', 'TE_154.pdf', 'TE_156.pdf', 'TE_153.pdf', 'TE_170.pdf', 'TE_166.pdf', 'TE_168.pdf', 'TE_169.pdf', 'TE_167.pdf', 'TE_174.pdf', 'TE_173.pdf', 'TE_172.pdf', 'TE_164.pdf', 'TE_165.pdf', 'TE_171.pdf', 'TE_163.pdf', 'TE_196.pdf', 'TE_189.pdf', 'TE_188.pdf', 'TE_190.pdf', 'TE_193.pdf', 'TE_194.pdf', 'TE_192.pdf', 'TE_191.pdf', 'TE_195.pdf', 'TE_187.pdf', 'TE_182.pdf', 'TE_181.pdf', 'TE_179.pdf', 'TE_180.pdf', 'TE_186.pdf', 'TE_185.pdf', 'TE_178.pdf', 'TE_177.pdf', 'TE_175.pdf', 'TE_184.pdf', 'TE_183.pdf', 'TE_176.pdf', 'TE_198.pdf', 'TE_136.pdf', 'TE_199.pdf', 'TE_133.pdf', 'TE_135.pdf', 'TE_139.pdf', 'TE_138.pdf', 'TE_134.pdf', 'TE_132.pdf', 'TE_137.pdf', 'TE_200.pdf', 'TE_197.pdf', 'TE_147.pdf', 'TE_145.pdf', 'TE_144.pdf', 'TE_146.pdf', 'TE_142.pdf', 'TE_151.pdf', 'TE_150.pdf', 'TE_143.pdf', 'TE_141.pdf', 'TE_149.pdf', 'TE_148.pdf', 'TE_140.pdf']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w-xofgUc_dL"
      },
      "source": [
        "def opencv_resize(image, ratio):\n",
        "    width = int(image.shape[1] * ratio)\n",
        "    height = int(image.shape[0] * ratio)\n",
        "    dim = (width, height)\n",
        "    return cv2.resize(image, dim, interpolation = cv2.INTER_AREA)"
      ],
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6OlxhOMfH2v"
      },
      "source": [
        "def plot_rgb(image):\n",
        "    plt.figure(figsize=(16,10))\n",
        "    return plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
      ],
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7eRiw3AfLdk"
      },
      "source": [
        "def plot_gray(image):\n",
        "    plt.figure(figsize=(16,10))\n",
        "    return plt.imshow(image, cmap='Greys_r')"
      ],
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7CBIovDgS44"
      },
      "source": [
        "# approximate the contour by a more primitive polygon shape\n",
        "def approximate_contour(contour):\n",
        "    peri = cv2.arcLength(contour, True)\n",
        "    return cv2.approxPolyDP(contour, 0.032 * peri, True)"
      ],
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNVeDgK9gWVp"
      },
      "source": [
        "def get_receipt_contour(contours):    \n",
        "    # loop over the contours\n",
        "    for c in contours:\n",
        "        approx = approximate_contour(c)\n",
        "        # if our approximated contour has four points, we can assume it is receipt's rectangle\n",
        "        if len(approx) == 4:\n",
        "            return approx"
      ],
      "execution_count": 492,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQIBKNUgmPo"
      },
      "source": [
        "def contour_to_rect(contour):\n",
        "    pts = contour.reshape(4, 2)\n",
        "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
        "    # top-left point has the smallest sum\n",
        "    # bottom-right has the largest sum\n",
        "    s = pts.sum(axis = 1)\n",
        "    rect[0] = pts[np.argmin(s)]\n",
        "    rect[2] = pts[np.argmax(s)]\n",
        "    # compute the difference between the points:\n",
        "    # the top-right will have the minumum difference \n",
        "    # the bottom-left will have the maximum difference\n",
        "    diff = np.diff(pts, axis = 1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "    return rect / resize_ratio"
      ],
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4DBl4xwgv6w"
      },
      "source": [
        "def wrap_perspective(img, rect):\n",
        "    # unpack rectangle points: top left, top right, bottom right, bottom left\n",
        "    (tl, tr, br, bl) = rect\n",
        "    # compute the width of the new image\n",
        "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "    # compute the height of the new image\n",
        "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "    # take the maximum of the width and height values to reach\n",
        "    # our final dimensions\n",
        "    maxWidth = max(int(widthA), int(widthB))\n",
        "    maxHeight = max(int(heightA), int(heightB))\n",
        "    # destination points which will be used to map the screen to a \"scanned\" view\n",
        "    dst = np.array([\n",
        "        [0, 0],\n",
        "        [maxWidth - 1, 0],\n",
        "        [maxWidth - 1, maxHeight - 1],\n",
        "        [0, maxHeight - 1]], dtype = \"float32\")\n",
        "    # calculate the perspective transform matrix\n",
        "    M = cv2.getPerspectiveTransform(rect, dst)\n",
        "    # warp the perspective to grab the screen\n",
        "    return cv2.warpPerspective(img, M, (maxWidth, maxHeight))"
      ],
      "execution_count": 494,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avsnec8Tg8l_"
      },
      "source": [
        "def bw_scanner(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    T = threshold_local(gray, 21, offset = 5, method = \"gaussian\")\n",
        "    return (gray > T).astype(\"uint8\") * 255"
      ],
      "execution_count": 495,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiLwoBsbtQ5y"
      },
      "source": [
        "def find_amounts(text):\n",
        "    amounts = re.findall(r'\\d+\\.\\d{2}\\b', text)\n",
        "    floats = [float(amount) for amount in amounts]\n",
        "    unique = list(dict.fromkeys(floats))\n",
        "    return unique"
      ],
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd6ipNORSZC7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "9a62494e-0f00-4c76-fd94-b5c1255d4cb2"
      },
      "source": [
        "Submission = pd.DataFrame(columns=['FileName', 'Total Amount'])\n",
        "\n",
        "dir_tmp = \"/content/drive/MyDrive/OCR_DataSet/tmp/\"\n",
        "dir_image = \"/content/drive/MyDrive/OCR_DataSet/image/\"\n",
        "i = 0\n",
        "\n",
        "for fn in files:\n",
        "    i = i +1\n",
        "    images = convert_from_path(folder + fn, dpi=100, output_folder=dir_tmp, fmt='jpg', last_page=1, first_page =0)\n",
        "    # image = convert_from_path(folder + fn, dpi=100, output_folder=dir_tmp, fmt='jpg', last_page=1, first_page =0, paths_only =True)\n",
        "    \n",
        "    # Get file name\n",
        "    base_filename = os.path.splitext(os.path.basename(fn))[0] + '.jpg' \n",
        "    print(\"bas_filename: \", base_filename)    \n",
        "\n",
        "    name_only = os.path.splitext(os.path.basename(fn))[0]\n",
        "    print(\"name_only: \", name_only)\n",
        "\n",
        "    for page in images:\n",
        "            page.save(os.path.join(dir_tmp, base_filename), 'JPEG')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####### Addition of new code\n",
        "    # imgfiles = [file for file in listdir(dir_tmp) if isfile(join(dir_tmp, file)) and file.endswith('.jpg')]   \n",
        "\n",
        "    file_name = dir_tmp + base_filename\n",
        "    image = cv2.imread(file_name)\n",
        "\n",
        "    # Downscale image as finding receipt contour is more efficient on a small image\n",
        "    # resize_ratio = 500 / image.shape[0]\n",
        "    resize_ratio = image.shape[1]//10,image.shape[0]//10\n",
        "    original = image.copy()\n",
        "    image = opencv_resize(image, resize_ratio)\n",
        "\n",
        "    # Convert to grayscale for further processing\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    plot_gray(gray)\n",
        "\n",
        "    # Get rid of noise with Gaussian Blur filter\n",
        "    # blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    blurred = cv2.GaussianBlur(gray, (11, 11), 0)\n",
        "    plot_gray(blurred)\n",
        "\n",
        "    # Detect white regions\n",
        "    rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
        "    dilated = cv2.dilate(blurred, rectKernel)\n",
        "    plot_gray(dilated)\n",
        "\n",
        "    # edged = cv2.Canny(dilated, 100, 200, apertureSize=3)\n",
        "    edged = cv2.Canny(gray, 75, 200)\n",
        "    plot_gray(edged)\n",
        "\n",
        "    # Detect all contours in Canny-edged image\n",
        "    # contours, hierarchy = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = sorted(contours[1], key = cv2.contourArea, reverse = True)[:5]\n",
        "\n",
        "    image_with_contours = cv2.drawContours(image.copy(), contours, -1, (0,255,0), 3)\n",
        "    plot_rgb(image_with_contours)\n",
        "\n",
        "    # Get 10 largest contours\n",
        "    largest_contours = sorted(contours, key = cv2.contourArea, reverse = True)[:10]\n",
        "    image_with_largest_contours = cv2.drawContours(image.copy(), largest_contours, -1, (0,255,0), 3)\n",
        "    plot_rgb(image_with_largest_contours)\n",
        "\n",
        "    # get_receipt_contour(largest_contours)\n",
        "\n",
        "    # receipt_contour = get_receipt_contour(largest_contours) \n",
        "    # image_with_receipt_contour = cv2.drawContours(image.copy(), [receipt_contour], -1, (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "    for c in contours:\n",
        "        ### Approximating the contour\n",
        "        #Calculates a contour perimeter or a curve length\n",
        "        peri = cv2.arcLength(c, True)\n",
        "        approx = cv2.approxPolyDP(c, 0.01 * peri, True)\n",
        "        # if our approximated contour has four points, then we\n",
        "        # can assume that we have found our screen\n",
        "        screenCnt = approx\n",
        "        if len(approx) == 4:\n",
        "            screenCnt = approx\n",
        "            break\n",
        "        # show the contour (outline) \n",
        "        # print(\"STEP 2: Finding Boundary\")\n",
        "    cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
        "    image_with_receipt_contour = cv2.resize(image,(image.shape[1],image.shape[0]))\n",
        "\n",
        "\n",
        "    plot_rgb(image_with_receipt_contour)\n",
        "\n",
        "    if  receipt_contour.any():\n",
        "        if receipt_contour.all():\n",
        "            scanned = wrap_perspective(original.copy(), contour_to_rect(receipt_contour))\n",
        "            plt.figure(figsize=(16,10))\n",
        "            plt.imshow(scanned)\n",
        "\n",
        "            result = bw_scanner(scanned)\n",
        "            plot_gray(result)\n",
        "          \n",
        "            output = Image.fromarray(result)\n",
        "            output.save('result.png')\n",
        "\n",
        "            file_name = \"result.png\"\n",
        "            image = cv2.imread(file_name, cv2.IMREAD_GRAYSCALE) \n",
        "            plot_gray(image)\n",
        "\n",
        "            d = pytesseract.image_to_data(output, output_type=Output.DICT)\n",
        "            n_boxes = len(d['level'])\n",
        "            boxes = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)\n",
        "            for i in range(n_boxes):\n",
        "                (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])    \n",
        "                boxes = cv2.rectangle(boxes, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                \n",
        "            plot_rgb(boxes)\n",
        "\n",
        "            extracted_text = pytesseract.image_to_string(image)\n",
        "            # print(extracted_text)\n",
        "\n",
        "            amounts = find_amounts(extracted_text)\n",
        "            # amounts\n",
        "\n",
        "            # max(amounts)\n",
        "\n",
        "            if amounts:\n",
        "\n",
        "                i_str = str(i)\n",
        "\n",
        "                # Submission[i].File_name = name_only+i_str\n",
        "                # Submission[i].Tot_amount = max(amounts)\n",
        "                \n",
        "                print(name_only, max(amounts))\n",
        "\n",
        "                # Submission[i] = pd.DataFrame({\"FileName\":[name_only],\n",
        "                #                      \"Total Amount\":[max(amounts)]})\n",
        "\n",
        "                Submission = Submission.append({'FileName':[name_only],\n",
        "                                  'Total Amount':[max(amounts)]}, ignore_index = True)\n",
        "\n",
        "# # rename columns \n",
        "# Submission = Submission.rename(columns={output.columns[0]: 'File Name'})\n",
        "# Submission = Submission.rename(columns={output.columns[1]: 'Total Amount'})\n",
        "\n",
        "# write output file to Google drive\n",
        "output_path = '/content/drive/MyDrive/PDF_OCR_FinalAssesment.csv'\n",
        "Submission.to_csv(output_path, index=False)"
      ],
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bas_filename:  TE_131.jpg\n",
            "name_only:  TE_131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-497-89a8a798876e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# image = opencv_resize(image, resize_ratio)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopencv_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Convert to grayscale for further processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-488-fec0631b5de7>\u001b[0m in \u001b[0;36mopencv_resize\u001b[0;34m(image, ratio)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopencv_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'tuple'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n-C0MqplmaY"
      },
      "source": [
        "#imgfiles = [file for file in listdir(dir_tmp) if isfile(join(dir_tmp, file)) and file.endswith('.jpg')]\n",
        "#print(imgfiles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeeG4cWYfPle"
      },
      "source": [
        "# file_name = dir_tmp + \"TE_160.jpg\"\n",
        "# image = cv2.imread(file_name)\n",
        "# # Downscale image as finding receipt contour is more efficient on a small image\n",
        "# resize_ratio = 500 / image.shape[0]\n",
        "# original = image.copy()\n",
        "# image = opencv_resize(image, resize_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE9qqviGfcgF"
      },
      "source": [
        "# # Convert to grayscale for further processing\n",
        "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "# plot_gray(gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF2iFZ_MfeAV"
      },
      "source": [
        "# # Get rid of noise with Gaussian Blur filter\n",
        "# blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "# plot_gray(blurred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-ag9rBCfiHj"
      },
      "source": [
        "# # Detect white regions\n",
        "# rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
        "# dilated = cv2.dilate(blurred, rectKernel)\n",
        "# plot_gray(dilated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVlH-opIfnFT"
      },
      "source": [
        "# edged = cv2.Canny(dilated, 100, 200, apertureSize=3)\n",
        "# plot_gray(edged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLd6zWonf1j7"
      },
      "source": [
        "cv2.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lwgK5Hdf2o6"
      },
      "source": [
        "# # Detect all contours in Canny-edged image\n",
        "# contours, hierarchy = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "# image_with_contours = cv2.drawContours(image.copy(), contours, -1, (0,255,0), 3)\n",
        "# plot_rgb(image_with_contours)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87tM7oOWgGgh"
      },
      "source": [
        "# # Get 10 largest contours\n",
        "# largest_contours = sorted(contours, key = cv2.contourArea, reverse = True)[:10]\n",
        "# image_with_largest_contours = cv2.drawContours(image.copy(), largest_contours, -1, (0,255,0), 3)\n",
        "# plot_rgb(image_with_largest_contours)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHL18BdXge9V"
      },
      "source": [
        "# get_receipt_contour(largest_contours)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip0bkC6dgjhf"
      },
      "source": [
        "## receipt_contour = get_receipt_contour(largest_contours)\n",
        "## image_with_receipt_contour = cv2.drawContours(image.copy(), [receipt_contour], -1, (0, 255, 0), 2)\n",
        "## plot_rgb(image_with_receipt_contour)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53RhbRJzg4vD"
      },
      "source": [
        "# scanned = wrap_perspective(original.copy(), contour_to_rect(receipt_contour))\n",
        "# plt.figure(figsize=(16,10))\n",
        "# plt.imshow(scanned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGZsVMCmg9kS"
      },
      "source": [
        "# result = bw_scanner(scanned)\n",
        "# plot_gray(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XshHU2WuhCbG"
      },
      "source": [
        "# output = Image.fromarray(result)\n",
        "# output.save('result.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu1G1C3Dsymx"
      },
      "source": [
        "# file_name = \"result.png\"\n",
        "# image = cv2.imread(file_name, cv2.IMREAD_GRAYSCALE) \n",
        "# plot_gray(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b87n3mmuqz8O"
      },
      "source": [
        "# d = pytesseract.image_to_data(output, output_type=Output.DICT)\n",
        "# n_boxes = len(d['level'])\n",
        "# boxes = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)\n",
        "# for i in range(n_boxes):\n",
        "#     (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])    \n",
        "#     boxes = cv2.rectangle(boxes, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "    \n",
        "# plot_rgb(boxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB4uoTVNtB--"
      },
      "source": [
        "# extracted_text = pytesseract.image_to_string(image)\n",
        "# print(extracted_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKXSxQg7tZKY"
      },
      "source": [
        "# amounts = find_amounts(extracted_text)\n",
        "# amounts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-UwPPJbtdbs"
      },
      "source": [
        "# max(amounts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnN9LzCTtm09"
      },
      "source": [
        "# df = pd.DataFrame(columns=['File Name', 'Total Amount'])\n",
        "# df1 = df = pd.DataFrame({\"File Name\":[base_filename],\n",
        "#                          \"Total Amount\":[max(amounts)]})\n",
        "# df1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}