{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "tom-and-jerry-hackerearth.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhaktaraj-Pooja/ML-Project/blob/main/tom_and_jerry_hackerearth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Wvx0ySHyjuH_"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "import cv2 as cv\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import cv2 \n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "      #for filename in filenames:\n",
        "       #print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0oAt4TGajuIN"
      },
      "source": [
        "traindf=pd.read_csv(\"/kaggle/input/detect-emotions-of-your-favorite-toons/96714c94-6-Dataset/Dataset/Train.csv\")\n",
        "print(traindf.shape)\n",
        "testdf=pd.read_csv(\"/kaggle/input/detect-emotions-of-your-favorite-toons/96714c94-6-Dataset/Dataset/Test.csv\")\n",
        "print(testdf.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xwv2mdHEjuIP"
      },
      "source": [
        "traindf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m3YtL3EojuIQ"
      },
      "source": [
        "'''\n",
        "import cv2\n",
        "vidcap = cv2.VideoCapture('detect-emotions-of-your-favorite-toons/96714c94-6-Dataset/Dataset/Train Tom and jerry.mp4')\n",
        "\n",
        "def getFrame(sec):\n",
        "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "    hasFrames,image = vidcap.read()\n",
        "    if hasFrames:\n",
        "        cv2.imwrite(\"/kaggle/input/detect-emotions-of-your-favorite-toons/frames/train_frames/\"+str(count)+\".jpg\", image) # save frame as JPG file\n",
        "    return hasFrames,image\n",
        "train_images =[]\n",
        "IMAGE_SIZE = (150,150)\n",
        "sec = 1\n",
        "frameRate = 1 #//it will capture image in each 0.5 second\n",
        "count=1\n",
        "success,image = getFrame(sec)\n",
        "while success:\n",
        "    count = count + 1\n",
        "    sec = sec + frameRate\n",
        "    sec = round(sec, 2)\n",
        "    success = getFrame(sec)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xrQIuOLMjuIS"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(x='Emotion', data=traindf,\n",
        "                   order=list(traindf['Emotion'].value_counts().sort_index().index) ,\n",
        "                   color='cyan')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7ZN_vWBhjuIT"
      },
      "source": [
        "traindf.loc[traindf['Frame_ID'] == 'frame0.jpg']['Emotion']\n",
        "class_names =np.unique(traindf['Emotion'])\n",
        "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "nb_classes = len(class_names)\n",
        "print(class_names_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wRs-Q5AVjuIV"
      },
      "source": [
        "\"\"\"\n",
        "import cv2\n",
        "vidcap = cv2.VideoCapture('detect-emotions-of-your-favorite-toons/96714c94-6-Dataset/Dataset/Test Tom and jerry.mp4')\n",
        "\n",
        "def getFrame(sec):\n",
        "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "    hasFrames,image = vidcap.read()\n",
        "    if hasFrames:\n",
        "        cv2.imwrite(\"/kaggle/input/detect-emotions-of-your-favorite-toons/frames/train_frames/\"+str(count)+\".jpg\", image) # save frame as JPG file\n",
        "    return hasFrames,image\n",
        "train_images =[]\n",
        "IMAGE_SIZE = (150,150)\n",
        "sec = 1\n",
        "frameRate = 1 #//it will capture image in each 0.5 second\n",
        "count=1\n",
        "success,image = getFrame(sec)\n",
        "while success:\n",
        "    count = count + 1\n",
        "    sec = sec + frameRate\n",
        "    sec = round(sec, 2)\n",
        "    success = getFrame(sec)\n",
        "    \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fEUupCWIjuIX"
      },
      "source": [
        "IMAGE_SIZE = (256, 256)\n",
        "dataset = '/kaggle/input/detect-emotions-of-your-favorite-toons/frames/train_frames'\n",
        "output = []\n",
        "train_images = []\n",
        "train_labels = []\n",
        "for files in tqdm(os.listdir(dataset)):\n",
        "    try:\n",
        "        label=class_names_label[traindf.loc[traindf['Frame_ID'] == files]['Emotion'].values[0]]\n",
        "    except:\n",
        "        #do nothing\n",
        "        a=1\n",
        "    img_path=os.path.join(dataset, files)\n",
        "    # Open and resize the img\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, IMAGE_SIZE) \n",
        "    # Append the image and its corresponding label to the output\n",
        "    train_images.append(image)\n",
        "    train_labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MyQ7S5ecjuIY"
      },
      "source": [
        "train_images = np.array(train_images, dtype = 'float32')/255\n",
        "train_labels = np.array(train_labels, dtype = 'int32') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jNV297-fjuIZ"
      },
      "source": [
        "IMAGE_SIZE = (256, 256)\n",
        "dataset = '/kaggle/input/detect-emotions-of-your-favorite-toons/frames/test_frames'\n",
        "output = []\n",
        "test_images = []\n",
        "for files in tqdm(os.listdir(dataset)):\n",
        "    img_path=os.path.join(dataset, files)\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, IMAGE_SIZE) \n",
        "    # Append the image and its corresponding label to the output\n",
        "    test_images.append(image)\n",
        "test_images = np.array(test_images, dtype = 'float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y3GYexVmjuIb"
      },
      "source": [
        "plt.imshow(test_images[25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j-AibgYhjuIc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(train_images,train_labels,test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "niZuWMXPjuId"
      },
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') \n",
        "y_train = y_train.astype('float32') \n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T3nmHQdqjuIf"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lRYc2QVWjuIf"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mNBASpXLjuIg"
      },
      "source": [
        "    from keras.models import Sequential\n",
        "    from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "    from keras.optimizers import SGD\n",
        "    from keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QFVn2hSyjuIh"
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32,(3,3), input_shape = (256,256, 3), activation = 'relu'))\n",
        "\n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "#Adding more layers \n",
        "classifier.add(Conv2D(32,(3,3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#Adding more layers \n",
        "\n",
        "classifier.add(Conv2D(32,(3,3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "classifier.add(Conv2D(32,(3,3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(output_dim = 300, activation = 'relu'))\n",
        "classifier.add(Dense(output_dim = 100, activation = 'relu'))\n",
        "classifier.add(Dense(output_dim = 5, activation = 'softmax'))\n",
        "\n",
        "# Compiling the CNN\n",
        "from keras import optimizers\n",
        "\n",
        "#o = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "classifier.compile(optimizer = Adam(lr=0.001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "epochs=50\n",
        "classifier.fit(x_train,\n",
        "             y_train,\n",
        "             batch_size=32,\n",
        "             nb_epoch=epochs,\n",
        "             verbose=1,\n",
        "             validation_data=(x_val,y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LxxSibUyjuIj"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BK2cb_fKjuIk"
      },
      "source": [
        "import pydot\n",
        "keras.utils.plot_model(classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kZIWdDs1juIk"
      },
      "source": [
        "scores = classifier.evaluate(x_val, y_val, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UeOQvzHejuIl"
      },
      "source": [
        "y_test_prob = classifier.predict(test_images)\n",
        "y_test_prob.round(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9rIz0_7RjuIm"
      },
      "source": [
        "y_test_pred = classifier.predict_classes(test_images)\n",
        "y_test_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GRdM7n_0juIn"
      },
      "source": [
        "elo = np.array(class_names)[y_test_pred]\n",
        "elo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Esz07-QZjuIo"
      },
      "source": [
        "f=95\n",
        "print(plt.imshow(test_images[f]),elo[f])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Rl7bg_uBjuIo"
      },
      "source": [
        "type(elo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nUPs0TubjuIp"
      },
      "source": [
        "df2 = testdf.assign(Emotion = elo) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r5CCo3T5juIq"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FRZ_lHOBjuIr"
      },
      "source": [
        "df2.to_csv('submission2.csv', header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PZi9he-ljuIr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}